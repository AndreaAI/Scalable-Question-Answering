{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the SQA Data\n",
    "\n",
    "In this notebook, we explore the SPARQL queries. Especially, we extract all the entities and relations present in the SQA dataset. Mainly to seed the Radom Walks thorughhe DBpedia graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "idata = open('lcquad_qaldformat.json', 'rt', encoding='utf-8')\n",
    "idata = json.load(idata)\n",
    "\n",
    "iquestions = idata['questions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the questions, the SPARQL queries and the answers. \n",
    "#The answers are either a list of entities, number (for How many .. questions) or a boolean.\n",
    "question_strings = []\n",
    "spqrql_queries = []\n",
    "answers = []\n",
    "\n",
    "qlens = []\n",
    "alens = []\n",
    "for iquestion in iquestions:\n",
    "    question_string = iquestion['question'][0]['string']\n",
    "    sparql_query = iquestion['query']['sparql']\n",
    "    answer = iquestion['answers']\n",
    "    qlens.append(len(iquestion['question']))\n",
    "    alens.append(len(answer))\n",
    "    question_strings.append(question_string)\n",
    "    spqrql_queries.append(sparql_query)\n",
    "    answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parse sparql\n",
    "#import sys\n",
    "#!{sys.executable} -m pip install rdflib\n",
    "import rdflib\n",
    "from rdflib.plugins.sparql.parser import parseQuery\n",
    "from pprint import pprint\n",
    "\n",
    "parsed_queries = []\n",
    "for query in spqrql_queries:\n",
    "    try:\n",
    "        query = query.replace('COUNT(?uri)', '(COUNT(*) AS ?callret)') #make the count queries compatible with rdflib \n",
    "        q = parseQuery(query)[1]\n",
    "        parsed_queries.append(q)\n",
    "    except:\n",
    "         print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdflib.term.URIRef('http://dbpedia.org/ontology/builder')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#example of parse query\n",
    "q = parseQuery('SELECT DISTINCT (COUNT(*) AS ?callret) WHERE { ?x <http://dbpedia.org/ontology/builder> <http://dbpedia.org/resource/PCL_Construction> . ?x <http://dbpedia.org/ontology/tenant> ?uri  . }')[1]\n",
    "\n",
    "q['where']['part'][0]['triples'][0][1]['part'][0]['part'][0]['part'] #extremely ugly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'DISTINCT': 4632, None: 368})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how often is the DISTINCT modifier present in the dataset. \n",
    "from collections import Counter\n",
    "\n",
    "modifiers = [q.modifier for q in parsed_queries]\n",
    "Counter(modifiers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'SelectQuery': 4632, 'AskQuery': 368})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print the query types in the dataset. \n",
    "query_types = [q.name for q in parsed_queries]\n",
    "Counter(query_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({2: 2103, 1: 1368, 3: 1529})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here, we look at how many triples there are in the SPARQL queries, where a triple is e.g. ?x rel subject\n",
    "triplets = [q['where']['part'][0]['triples'] for q in parsed_queries]\n",
    "Counter([len(triple) for triple in triplets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'evar': rdflib.term.Variable('callret'),\n",
      "  'expr': {'expr': {'expr': {'expr': {'expr': {'expr': {'distinct': ([], {}),\n",
      "                                                        'vars': '*'}}}}}}}]\n",
      "'projection'\n",
      "[vars_{'var': rdflib.term.Variable('uri')}]\n"
     ]
    }
   ],
   "source": [
    "projection = [q.get('projection', None) for q in parsed_queries]\n",
    "pprint(projection[15])\n",
    "pprint(projection[16])\n",
    "pprint(projection[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_triplets = []\n",
    "for triples in triplets:\n",
    "    parsed_triples = []\n",
    "    for triple in triples:\n",
    "        rel = triple[1]['part'][0]['part'][0]['part']\n",
    "        parsed_triples.append((triple[0], rel, triple[2]))\n",
    "    parsed_triplets.append(parsed_triples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(rdflib.term.Variable('x'),\n",
       "  rdflib.term.URIRef('http://dbpedia.org/ontology/ingredient'),\n",
       "  rdflib.term.URIRef('http://dbpedia.org/resource/Shallot')),\n",
       " (rdflib.term.Variable('x'),\n",
       "  rdflib.term.URIRef('http://dbpedia.org/ontology/country'),\n",
       "  rdflib.term.Variable('uri')),\n",
       " (rdflib.term.Variable('uri'),\n",
       "  rdflib.term.URIRef('http://www.w3.org/1999/02/22-rdf-syntax-ns#type'),\n",
       "  rdflib.term.URIRef('http://dbpedia.org/ontology/Country'))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_triplets[144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<http://dbpedia.org/ontology/ingredient>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_triplets[144][0][1].n3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4156 597\n"
     ]
    }
   ],
   "source": [
    "#get all the entities present in the SQA dataset - use them later as seeds for the random walks\n",
    "entities = set()\n",
    "relations = set()\n",
    "\n",
    "for triples in parsed_triplets:\n",
    "    for e1, r, e2 in triples:\n",
    "        #add all entities which are not variables\n",
    "        if not e1.n3() == '?uri' and not e1.n3() == '´?x':\n",
    "            entities.add(e1.n3())\n",
    "        if not e2.n3() == '?uri' and not e2.n3() == '´?x':\n",
    "            entities.add(e2.n3())\n",
    "        relations.add(r.n3())\n",
    "print(len(entities), len(relations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<http://dbpedia.org/resource/John_Smith_Griffin>',\n",
       " '<http://dbpedia.org/resource/Kimberly_Stewart>',\n",
       " '<http://dbpedia.org/resource/Drum_kit>',\n",
       " '<http://dbpedia.org/resource/Marvin_Bush>',\n",
       " '<http://dbpedia.org/resource/New_Jersey>',\n",
       " '<http://dbpedia.org/resource/Beşiktaş_JK_(wheelchair_basketball)>',\n",
       " '<http://dbpedia.org/resource/Martin_Pugh>',\n",
       " '<http://dbpedia.org/ontology/Disease>',\n",
       " '<http://dbpedia.org/resource/Boston_Bruins>',\n",
       " '<http://dbpedia.org/resource/Charles_LeMaire>']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.sample(list(entities), k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of different dataset files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the list of entities in the SQA datafolder\n",
    "ofile = open('sqa_entities.txt', 'wt', encoding='utf-8')\n",
    "ofile.writelines([x + '\\n' for x in list(entities)])\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the list of questions in the SQA datafolder\n",
    "ofile = open('sqa_questions.txt', 'wt', encoding='utf-8')\n",
    "ofile.writelines([x + '\\n' for x in question_strings])\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the list of SPARQL queries in the SQA datafolder\n",
    "ofile = open('sqa_sparql.txt', 'wt', encoding='utf-8')\n",
    "ofile.writelines([x[0][1].n3() + '\\n' for x in parsed_triplets])\n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the questions, the SPARQL queries and the answers, including index\n",
    "question_strings = []\n",
    "spqrql_queries = []\n",
    "answers = []\n",
    "\n",
    "qlens = []\n",
    "alens = []\n",
    "\n",
    "ofile = open('sqa_questions_index.txt', 'wt', encoding='utf-8')\n",
    "ofile2 = open('sqa_sparql_index.txt', 'wt', encoding='utf-8')\n",
    "for i, iquestion in enumerate(iquestions):\n",
    "    question_string = iquestion['question'][0]['string']\n",
    "    sparql_query = iquestion['query']['sparql']\n",
    "    answer = iquestion['answers']\n",
    "    qlens.append(len(iquestion['question']))\n",
    "    alens.append(len(answer))\n",
    "    question_strings.append(question_string)\n",
    "    spqrql_queries.append(sparql_query)\n",
    "    answers.append(answer)\n",
    "    ofile.writelines(str(i) + ',' + question_string + '\\n' )\n",
    "    ofile2.writelines(str(i) + ',' + sparql_query + '\\n' )\n",
    "    \n",
    "ofile.close()\n",
    "ofile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store the list of SPARQL queries with index\n",
    "ofile = open('sqa_sparql_parsed.txt', 'wt', encoding='utf-8')\n",
    "for i, x in enumerate(parsed_triplets):\n",
    "    ofile.writelines(str(i) + ',' + str(x) + '\\n')\n",
    "    \n",
    "ofile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4155 597\n"
     ]
    }
   ],
   "source": [
    "#get all the entities present in the SQA dataset - use them later as seeds for the random walks\n",
    "entities = set()\n",
    "relations = set()\n",
    "\n",
    "ofile = open('sqa_entities_index.txt', 'wt', encoding='utf-8')\n",
    "ofile2 = open('sqa_relations_index.txt', 'wt', encoding='utf-8')\n",
    "\n",
    "for i, triples in enumerate(parsed_triplets):\n",
    "    for e1, r, e2 in triples:\n",
    "        #add all entities which are not variables\n",
    "        if not e1.n3() == '?uri' and not e1.n3() == '?x':\n",
    "            entities.add(e1.n3())\n",
    "            ofile.writelines(str(i) + ',' + e1.n3() + '\\n')\n",
    "        if not e2.n3() == '?uri' and not e2.n3() == '?x':\n",
    "            entities.add(e2.n3())\n",
    "            ofile.writelines(str(i) + ',' + e2.n3() + '\\n')\n",
    "        relations.add(r.n3())\n",
    "        ofile2.writelines(str(i) + ',' + r.n3() + '\\n')\n",
    "print(len(entities), len(relations))\n",
    "ofile.close()\n",
    "ofile2.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
